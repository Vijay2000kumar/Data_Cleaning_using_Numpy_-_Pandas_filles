# -*- coding: utf-8 -*-
"""Type_Casting_Pandas Data Cleaning-1.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1DkoJN079CdrBYBRiCe9E43lMwWUMIp6e
"""

# import required lilbrairies
import pandas as pd
import numpy as np

#read the csv file
df=pd.read_csv("https://raw.githubusercontent.com/mramshaw/Data-Cleaning/master/Datasets/BL-Flickr-Images-Book.csv")

#to see ,we can use sample(), df.head(),df.tail()
df

df.sample(5)

df.tail(10)

# to see shape of data
df.shape

#to see stastiticscs informations
df.describe()

# to see metadata
df.info

# to see in short form and datatype
df.info()

# to see columns name
df.columns

# Replace whitespace in column names with underscores
df.columns = df.columns.str.replace(" ", "_")
df

"""As per my observation i identify some error in data:

1- columns name has whitespaces

2- colums Edition Statement, Corporate Author, Corporate Contributors, Former owner, Engraver

['Edition Statement',
...            'Corporate Author',
...            'Corporate Contributors',
...            'Former owner',
...            'Engraver',
...            'Contributors',
...            'Issuance type',
...            'Shelfmarks']
"""

# now deling with null values ( NaN) related columns
# we can drop columns from the dateset when it has more then 80% has null values or even when column data is not relavant
drop_df=df.drop(['Edition_Statement','Title', 'Author','Contributors','Corporate_Author','Corporate_Contributors','Former_owner',
       'Engraver','Issuance_type',  'Shelfmarks'],
      axis=1)

drop_df.columns

#to check any null values
drop_df.notnull()

#In databases, indexing is used to speed up access to data. By creating an index of the data, the database can quickly find the desired information without having to scan the entire database.
drop_df['Identifier'].is_unique

#we can use "Identifier" as index for getting data
drop_df = drop_df.set_index('Identifier')
drop_df.head()

"""The code df.set_index('Identifier', inplace=True) sets the Identifier column as the index of the DataFrame df. The inplace=True parameter tells Pandas to modify the existing DataFrame instead of creating a new one.

When a column is set as the index, it is no longer considered a column in the DataFrame. Instead, it becomes the row labels. This means that you can access the rows in the DataFrame by their Identifier values, instead of their row numbers.

loc() and iloc() are two methods in Pandas that are used to select rows and columns from a DataFrame. They are very similar, but there are some key differences between them.

loc() is label-based indexing, while iloc() is integer-based indexing. This means that loc() uses the row and column names to select data, while iloc() uses the row and column indexes.
"""

#using loc{key_based} select the raw
drop_df.loc[206]

# usig iloc[ index] or entry based select the raw
drop_df.iloc[1]

"""The df.get_dtype_counts() method in Pandas returns a Series object that contains the count of each data type in the DataFrame df. The Series object has the data type dtype and the index is the name of the data type."""

drop_df.get_dtype_count()

#now try to clean date_of_publication coulunms values
drop_df.loc[1905:, 'Date_of_Publication'].head(10)

regex = r'^(\d{4})'
extr = drop_df['Date_of_Publication'].str.extract(r'^(\d{4})', expand=False)
extr.head()

"""The code regex = r'^(\d{4})' defines a regular expression that matches a four-digit number at the beginning of a string. The \d metacharacter matches any digit, and the {4} quantifier matches the previous metacharacter four times.

The code extr = df['Date of Publication'].str.extract(r'^(\d{4})', expand=False) uses the str.extract() method to extract the four-digit number from the Date of Publication column in the DataFrame df. The expand=False parameter tells Pandas to return a Series object with the extracted values, instead of expanding the Series object to a DataFrame with one column for each extracted value.

The code extr.head() prints the first five rows of the Series object extr.
"""

#convert these to a numeric type and copy them back:
drop_df['Date_of_Publication'] = pd.to_numeric(extr)
drop_df['Date_of_Publication'].dtype

#cleaning the place of publication column
drop_df['Place_of_Publication'].head(10)

pob = drop_df['Place_of_Publication']
London = pob.str.contains('London')
London[:5]

"""
Sure, I can help you with that.

The code pub = df['Place of Publication'] creates a new variable called pub that contains the Place of Publication column from the DataFrame df.

The code london = pub.str.contains('London') uses the str.contains() method to check if the Place of Publication column contains the string "London". The str.contains() method returns a Boolean Series object, where each value is True if the corresponding value in the Place of Publication column contains the string "London" and False otherwise.

The code london[:5] prints the first 5 values of the Boolean Series object london."""

oxford = pob.str.contains('Oxford')
drop_df['Place_of_Publication'] = np.where(London, 'London',
                                    np.where(oxford, 'Oxford',
                                            pob.str.replace('-', ' ')))
drop_df['Place_of_Publication'].head()

drop_df['Publisher']

drop_df["Publisher"] =str(drop_df["Publisher"])
drop_df["Publisher"] =drop_df["Publisher"].map(str.strip)

# to save clean data in csv formate
drop_df.to_csv("/content/sample_data/clean data csv file.csv")

dfclean=pd.read_csv("/content/sample_data/clean data csv file.csv")
dfclean

"""The code df["Publisher"] = df["Publisher"].map(str.strip) uses the map() function to apply the str.strip() method to the Publisher column in the DataFrame df. The str.strip() method removes any leading and trailing whitespace from a string."""

olympics_df=pd.read_csv('https://raw.githubusercontent.com/mramshaw/Data-Cleaning/master/Datasets/olympics.csv',header=1)
olympics_df

new_names={'Unnamed: 0': 'Country','? Summer': 'Summer Olympics','01 !': 'Gold','02 !': 'Silver','03 !': 'Bronze','? Winter': 'Winter Olympics','01 !.1': 'Gold.1','02 !.1': 'Silver.1','03 !.1': 'Bronze.1','? Games': '# Games','01 !.2': 'Gold.2','02 !.2': 'Silver.2','03 !.2': 'Bronze.2'}

olympics_df.rename(columns=new_names, inplace=True)
olympics_df.head()

"""Using the columns attribute: The columns attribute is a list of the column names in a DataFrame. You can use this attribute to rename the columns by assigning a new list of column names to it. For example, the following code renames the columns in the DataFrame df to the following:"""

